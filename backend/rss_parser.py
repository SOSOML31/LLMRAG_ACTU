import feedparser  # Module pour analyser les flux RSS
import requests  # Module pour effectuer des requ√™tes HTTP
from bs4 import BeautifulSoup  # Module pour extraire du texte HTML
from database import SessionLocal, Article  # Importer la connexion √† PostgreSQL et le mod√®le Article


##############################################################################################################################################################################
##############################################################################################################################################################################
##############################################################################################################################################################################
#        üéØ Ce script r√©cup√®re des articles depuis un flux RSS et les stocke dans PostgreSQL et ChromaDB.                         ###########################################
##############################################################################################################################################################################
##############################################################################################################################################################################
##############################################################################################################################################################################
##############################################################################################################################################################################

def fetch_rss_articles(rss_url):
    """
    üìå Cette fonction :
    1Ô∏è‚É£ T√©l√©charge le flux RSS depuis une URL donn√©e.
    2Ô∏è‚É£ Extrait le contenu des articles en HTML et le convertit en texte.
    3Ô∏è‚É£ V√©rifie si l'article existe d√©j√† en base de donn√©es (PostgreSQL).
    4Ô∏è‚É£ Si l'article est nouveau, il est ajout√© √† PostgreSQL.
    """

    session = SessionLocal()  # Ouvrir une session de connexion √† PostgreSQL
    feed = feedparser.parse(rss_url)  # Lire et parser le flux RSS

    for entry in feed.entries:  # Boucle sur chaque article du flux RSS

        # 1Ô∏è‚É£ R√©cup√©rer le contenu de l'article via son lien
        response = requests.get(entry.link)
        soup = BeautifulSoup(response.text, "html.parser")  # Parser le HTML de l'article

        # 2Ô∏è‚É£ Extraire le texte des balises <p> pour obtenir uniquement le contenu
        text = " ".join([p.text for p in soup.find_all("p")])

        # 3Ô∏è‚É£ V√©rifier si l'article est d√©j√† en base (on v√©rifie via l'URL unique)
        existing_article = session.query(Article).filter_by(url=entry.link).first()

        if not existing_article:  # Si l'article n'est PAS encore dans la base
            # 4Ô∏è‚É£ Cr√©er un nouvel objet Article pour le stocker dans PostgreSQL
            new_article = Article(title=entry.title, url=entry.link, content=text)
            session.add(new_article)  # Ajouter l'article √† la session SQL
            session.commit()  # Enregistrer dans la base
            print(f"‚úÖ Article ajout√©: {entry.title}")  # Affichage en console
        else:
            print(f"‚ö†Ô∏è Article d√©j√† pr√©sent en base: {entry.title}")  # D√©tection des doublons

    session.close()  # Fermer la connexion PostgreSQL
    print("‚úÖ Tous les articles ont √©t√© trait√©s.")  # Indiquer la fin du processus


# üöÄ Lancement du script avec l'URL du flux RSS
fetch_rss_articles("https://www.france24.com/fr/rss")