import ollama
def ask_ollama(query, context):
    ### Envoie une question Ã  Ollama en utilisant un contexte global
    prompt = f"""Voici les derniÃ¨res actualitÃ©s importantes :
    {context}
    En te basant sur ces informations, rÃ©ponds Ã  la question suivante : {query}
    ğŸ“¢ **Consigns :**  
    - RÃ©ponds comme une **journaliste** ğŸ“°.  
    - ** Ne dÃ©passe pas 150 caractÃ¨res** â³.  
    - ** Indique la date de chaque actualitÃ©, en priorisant celles du 6 fÃ©vrier** ğŸ“….  
    - ** Si tu comprend pas ou que tu as pas de sujet direct avec la question {query} dit vous pouvez reformuler**.  
    """
    try:
        response = ollama.chat(model="mistral", messages=[{"role": "user", "content": prompt}])
        return response.get("message", {}).get("content", "Aucune rÃ©ponse reÃ§ue d'Ollama.")
    except Exception as e:
        return f"âŒ Erreur Ollama : {str(e)}"

if __name__ == "__main__":
    test_response = ask_ollama("Quels sont les derniers Ã©vÃ©nements mondiaux ?", "Voici un contexte fictif.")
    print(f"ğŸ§  RÃ©ponse d'Ollama : {test_response}")