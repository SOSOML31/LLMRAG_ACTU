import ollama


def ask_ollama(query, context):
    """Envoie une question √† Ollama en utilisant un contexte global."""
    prompt = f"""Voici les derni√®res actualit√©s importantes :
    {context}

    En te basant sur ces informations, r√©ponds √† la question suivante : {query}
    """

    try:
        response = ollama.chat(model="mistral", messages=[{"role": "user", "content": prompt}])
        return response.get("message", {}).get("content", "Aucune r√©ponse re√ßue d'Ollama.")
    except Exception as e:
        return f"‚ùå Erreur Ollama : {str(e)}"


# Test manuel
if __name__ == "__main__":
    test_response = ask_ollama("Quels sont les derniers √©v√©nements mondiaux ?", "Voici un contexte fictif.")
    print(f"üß† R√©ponse d'Ollama : {test_response}")